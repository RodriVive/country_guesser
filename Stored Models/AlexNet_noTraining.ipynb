{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t84tK2fjAGux"
      },
      "source": [
        "# EECS 442 FINAL: Geoguessr Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8zMyTMC0VDm"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-re6JnCtDiqJ",
        "outputId": "79ae2741-e52c-4ab5-d9a7-530681ffb4b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "# Run the command in the terminal if it failed on local Jupyter Notebook, remove \"!\" before each line\n",
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mc2dzDlI_-6x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # Displays a progress bar\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WvC_h1RpCuXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddbc6f1d-46cd-428f-89c1-ab724adc5484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the GPU. You are good to go!\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"Using the GPU. You are good to go!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"Using the CPU. Overall speed may be slowed down\")\n",
        "    device = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMKs1--aAe9c"
      },
      "source": [
        "## Loading Dataset\n",
        "Mount the cwd to drive, access the train folder and load the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Tbwq9R1cAbnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7688bc4-00f8-450c-b909-09e657538851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/442final/train/resized_countries_reshape\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 \n",
            "17975\n",
            "17975\n",
            "/content/drive/MyDrive/442final/train/resized_countries_reshape\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 \n",
            "7171\n",
            "7171\n",
            "Number of training images 17975, number of testing images 7171\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !pip install gitpython > /dev/null 2>&1\n",
        "# !apt-get install -y -qq git > /dev/null 2>&1\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# print(os.getcwd())\n",
        "# ! ls\n",
        "# ! cd drive/MyDrive/442final\n",
        "# print(os.getcwd())\n",
        "\n",
        "data_directory = \"/drive/MyDrive/442final/train/resized_countries_reshape\"\n",
        "\n",
        "batch_size = 32\n",
        "img_width = 148\n",
        "img_height = 64\n",
        "epochs = 30\n",
        "\n",
        "img_target_scale = 0.2\n",
        "img_target_width = int(math.floor(img_width * img_target_scale))\n",
        "img_target_height= int(math.floor(img_height * img_target_scale))\n",
        "\n",
        "class get_Images(Dataset):\n",
        "  def __init__(self, root_dir, split='train', percentage=0.7, transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        root_dir: the directory of the dataset\n",
        "        split: \"train\" or \"val\"\n",
        "        transform: pytorch transformations.\n",
        "    \"\"\"\n",
        "    self.files = []\n",
        "    self.labels = []\n",
        "\n",
        "    # if split=='val':\n",
        "    #   percentage = 1 - percentage\n",
        "\n",
        "    self.transform = transform\n",
        "    print(root_dir)\n",
        "    for idx, country in enumerate(os.listdir(root_dir)):\n",
        "      print(idx, end=' ')\n",
        "      # Check if the item is a directory\n",
        "      files_in_dir = np.load(root_dir+'/'+country).astype(np.float32)\n",
        "      # print(files_in_dir.dtype)\n",
        "      # Randomly sample a certain percentage of files\n",
        "      num_files_to_take = int(len(files_in_dir) * percentage)\n",
        "      # Append the sampled file paths to the list\n",
        "      if split=='train':\n",
        "        self.files.extend(files_in_dir[:num_files_to_take])\n",
        "      else:\n",
        "        num_files = len(files_in_dir)\n",
        "        self.files.extend(files_in_dir[num_files - num_files_to_take:])\n",
        "\n",
        "      # self.files.extend(glob.glob(os.path.join(root_dir, country, '*.jpg')))\n",
        "      self.labels.extend([idx] * num_files_to_take)\n",
        "    print()\n",
        "    print(len(self.files))\n",
        "    print(len(self.labels))\n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # img_path = self.files[idx]\n",
        "    label = self.labels[idx]\n",
        "    # img = Image.open(img_path)\n",
        "    # if self.transform:\n",
        "    #     img = self.transform(img)\n",
        "    return {'image': self.files[idx], 'label': label}\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "###########################################################################\n",
        "# TODO: Construct the dataloader                                          #\n",
        "# For the train_loader, please use a batch size of 4 and set shuffle True #\n",
        "# For the val_loader, please use a batch size of 5 and set shuffle False  #\n",
        "# Hint: You'll need to create instances of the class above, name them as  #\n",
        "# tr_dt and te_dt. The dataloaders should be named as train_loader and    #\n",
        "# test_loader. You also need to include transform in your class           #\n",
        "#instances                                                                #\n",
        "###########################################################################\n",
        "\n",
        "tr_dt = get_Images(os.getcwd() + data_directory, split='train', percentage=0.5,  transform=transform)\n",
        "te_dt = get_Images(os.getcwd() + data_directory, split='val', percentage=0.2, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(tr_dt, batch_size=4, shuffle=True)\n",
        "test_loader = DataLoader(te_dt, batch_size=5, shuffle=False)\n",
        "\n",
        "###########################################################################\n",
        "#                              END OF YOUR CODE                           #\n",
        "###########################################################################\n",
        "\n",
        "print('Number of training images {}, number of testing images {}'.format(len(tr_dt), len(te_dt)))\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6rcDO7VCQ_q"
      },
      "source": [
        "## Model\n",
        "CHANGE THIS TO GET THE MODEL TO RUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Hz0BSR9xCNiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18ce17e-7d92-4900-a168-d6ce10d2ea35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:06<00:00, 37.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=55, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ##############################################################################\n",
        "        # TODO: Design your own network, define layers here.                          #\n",
        "        # Here We provide a sample of two-layer fc network from HW4 Part3.           #\n",
        "        # Your solution, however, should contain convolutional layers.               #\n",
        "        # Refer to PyTorch documentations of torch.nn to pick your layers.           #\n",
        "        # (https://pytorch.org/docs/stable/nn.html)                                  #\n",
        "        # Some common choices: Linear, Conv2d, ReLU, MaxPool2d, AvgPool2d, Dropout   #\n",
        "        # If you have many layers, use nn.Sequential() to simplify your code         #\n",
        "        ##############################################################################\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv_relu_stack = nn.Sequential(\n",
        "            nn.Conv2d(3, 4, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            # nn.AvgPool2d(kernel_size=5, stride=3),\n",
        "            nn.Conv2d(4, 4, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=20, stride=3),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2352 , 128),  # Adjust the input size according to your desired dimensions\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 55)\n",
        "          )\n",
        "        ##############################################################################\n",
        "        #                             END OF YOUR CODE                               #\n",
        "        ##############################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        ##############################################################################\n",
        "        # TODO: Design your own network, implement forward pass here                 #\n",
        "        ##############################################################################\n",
        "        x = self.conv_relu_stack(x)\n",
        "        return x\n",
        "        ##############################################################################\n",
        "        #                             END OF YOUR CODE                               #\n",
        "        ##############################################################################\n",
        "\n",
        "# model = Network().to(device)\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "print(alexnet)\n",
        "\n",
        "# Freeze all layers except the last three\n",
        "for param in alexnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the last three layers to be trainable\n",
        "num_features = alexnet.classifier[6].in_features\n",
        "alexnet.classifier[6] = nn.Linear(num_features, 55)  # Change the output size to 55 classes\n",
        "\n",
        "# Print the modified AlexNet architecture\n",
        "print(alexnet)\n",
        "criterion = nn.CrossEntropyLoss() # Specify the loss layer\n",
        "# print('Your network:')\n",
        "# print(summary(model, (3,148,64), device=device)) # visualize your model\n",
        "\n",
        "##############################################################################\n",
        "# TODO: Modify the lines below to experiment with different optimizers,      #\n",
        "# parameters (such as learning rate) and number of epochs.                   #\n",
        "##############################################################################\n",
        "# Set up optimization hyperparameters\n",
        "learning_rate, weight_decay, num_epoch = 0.001, 0.0001, 10\n",
        "optimizer = optim.Adam(alexnet.parameters(), learning_rate)\n",
        "##############################################################################\n",
        "#                             END OF YOUR CODE                               #\n",
        "##############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq9fTZiuDJ3I"
      },
      "source": [
        "Run the cell below to start your training, we expect you to achieve over **85%** on the test set. A valid solution that meet the requirement take no more than **10 minutes** on normal PC Intel core CPU setting. If your solution takes too long to train, try to simplify your model or reduce the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOFaEvBDDHzQ",
        "scrolled": true,
        "outputId": "e8dcea4b-767c-4e51-cee9-6ef404a5208d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "-----------------Epoch = 1-----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:09<00:00, 474.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 loss:3.081918734574668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:04<00:00, 1104.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1904867872044506\n",
            "\n",
            " Evaluate on validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1435/1435 [00:01<00:00, 1011.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1684562822479431\n",
            "-----------------Epoch = 2-----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:09<00:00, 467.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 2 loss:3.081823125859606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:03<00:00, 1135.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1904867872044506\n",
            "\n",
            " Evaluate on validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1435/1435 [00:01<00:00, 1047.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1684562822479431\n",
            "-----------------Epoch = 3-----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:10<00:00, 422.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 3 loss:3.081855758328304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:04<00:00, 1050.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1904867872044506\n",
            "\n",
            " Evaluate on validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1435/1435 [00:01<00:00, 948.53it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1684562822479431\n",
            "-----------------Epoch = 4-----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:09<00:00, 470.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 4 loss:3.0818783488069896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:06<00:00, 674.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1904867872044506\n",
            "\n",
            " Evaluate on validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1435/1435 [00:01<00:00, 957.76it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1684562822479431\n",
            "-----------------Epoch = 5-----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:09<00:00, 498.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 5 loss:3.081874860834428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:04<00:00, 958.55it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1904867872044506\n",
            "\n",
            " Evaluate on validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1435/1435 [00:01<00:00, 1010.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1684562822479431\n",
            "-----------------Epoch = 6-----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:09<00:00, 481.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 6 loss:3.081861820521225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:04<00:00, 1045.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1904867872044506\n",
            "\n",
            " Evaluate on validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1435/1435 [00:01<00:00, 1032.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1684562822479431\n",
            "-----------------Epoch = 7-----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:09<00:00, 471.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 7 loss:3.081851447058297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:03<00:00, 1144.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1904867872044506\n",
            "\n",
            " Evaluate on validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1435/1435 [00:01<00:00, 1032.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1684562822479431\n",
            "-----------------Epoch = 8-----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:09<00:00, 466.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 8 loss:3.081858671104107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:03<00:00, 1132.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1904867872044506\n",
            "\n",
            " Evaluate on validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1435/1435 [00:01<00:00, 1061.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1684562822479431\n",
            "-----------------Epoch = 9-----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:09<00:00, 471.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 9 loss:3.0819053789430795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:04<00:00, 1119.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1904867872044506\n",
            "\n",
            " Evaluate on validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1435/1435 [00:01<00:00, 951.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1684562822479431\n",
            "-----------------Epoch = 10-----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:09<00:00, 461.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 10 loss:3.0818562983511604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4494/4494 [00:04<00:00, 1061.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1904867872044506\n",
            "\n",
            " Evaluate on validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1435/1435 [00:01<00:00, 821.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation accuracy: 0.1684562822479431\n",
            "Done!\n",
            "\n",
            " Evaluate on test set\n",
            "CPU times: user 2min 25s, sys: 2.68 s, total: 2min 28s\n",
            "Wall time: 2min 35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "def train(model, trainloader, valloader, num_epoch=10):  # Train the model\n",
        "    print(\"Start training...\")\n",
        "    trn_loss_hist = []\n",
        "    trn_acc_hist = []\n",
        "    val_acc_hist = []\n",
        "    model.train()  # Set the model to training mode\n",
        "    for i in range(num_epoch):\n",
        "        running_loss = []\n",
        "        print('-----------------Epoch = %d-----------------' % (i+1))\n",
        "        # print(len(tqdm(trainloader)))\n",
        "        # for i in tqdm(trainloader):\n",
        "        #   print(i)\n",
        "        for input in tqdm(trainloader):\n",
        "            # print(batch, label)\n",
        "            # print(batch)\n",
        "            batch, label = input['image'], input['label']\n",
        "            # print(batch)\n",
        "            # print(label)\n",
        "            batch = batch.to(device)\n",
        "            label = label.to(device)\n",
        "            optimizer.zero_grad()  # Clear gradients from the previous iteration\n",
        "            # This will call Network.forward() that you implement\n",
        "            pred = model(batch)\n",
        "            loss = criterion(pred, label)  # Calculate the loss\n",
        "            running_loss.append(loss.item())\n",
        "            loss.backward()  # Backprop gradients to all tensors in the network\n",
        "            optimizer.step()  # Update trainable weights\n",
        "        print(\"\\n Epoch {} loss:{}\".format(i+1, np.mean(running_loss)))\n",
        "\n",
        "        # Keep track of training loss, accuracy, and validation loss\n",
        "        trn_loss_hist.append(np.mean(running_loss))\n",
        "        trn_acc_hist.append(evaluate(model, trainloader))\n",
        "        print(\"\\n Evaluate on validation set...\")\n",
        "        val_acc_hist.append(evaluate(model, valloader))\n",
        "    print(\"Done!\")\n",
        "    return trn_loss_hist, trn_acc_hist, val_acc_hist\n",
        "\n",
        "\n",
        "def evaluate(model, loader):  # Evaluate accuracy on validation / test set\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    with torch.no_grad():  # Do not calculate grident to speed up computation\n",
        "        for input in tqdm(loader):\n",
        "            batch, label = input['image'], input['label']\n",
        "            batch = batch.to(device)\n",
        "            label = label.to(device)\n",
        "            pred = model(batch)\n",
        "            correct += (torch.argmax(pred, dim=1) == label).sum().item()\n",
        "        acc = correct/len(loader.dataset)\n",
        "        print(\"\\n Evaluation accuracy: {}\".format(acc))\n",
        "        return acc\n",
        "\n",
        "\n",
        "trn_loss_hist, trn_acc_hist, val_acc_hist = train(model, train_loader,\n",
        "                                                  test_loader, num_epoch)\n",
        "\n",
        "##############################################################################\n",
        "# TODO: Note down the evaluation accuracy on test set                        #\n",
        "##############################################################################\n",
        "print(\"\\n Evaluate on test set\")\n",
        "# evaluate(model, testloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwDhwaydQR1Q"
      },
      "source": [
        "Once your training is complete, run the cell below to visualize the training and validation accuracies across iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1lYqngdtPQB8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "d57e0cdf-bda7-499e-a115-5964b60f2859"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "##############################################################################\n",
        "# TODO: Submit the accuracy plot                                             #\n",
        "##############################################################################\n",
        "# visualize the training / validation accuracies\n",
        "x = np.arange(num_epoch)\n",
        "# train/val accuracies for MiniVGG\n",
        "plt.figure()\n",
        "plt.plot(x, trn_acc_hist)\n",
        "plt.plot(x, val_acc_hist)\n",
        "plt.legend(['Training', 'Validation'])\n",
        "plt.xticks(x)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('fashion MNIST Classification')\n",
        "plt.gcf().set_size_inches(10, 5)\n",
        "plt.savefig('part1.png', dpi=300)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "9d34995e9b9aacf7236904ea7ddf7585a36f6be47e873dd30641939c3248d078"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}